# E6-Protecting-scientific-data-when-using-generative-AI
Summary of how researchersâ€™ data protection obligations may conflict with their use of public GenAI tools



| S#  | User Story | Current Problem | User Goal |
|----|----|----|-----|
|S74 | [As a researcher, I want to predict which participants in my study are most likely to benefit from a given drug based on their genetics (from whole genome sequencing), clinical records (from electronic health records), and other health information (from questionnaires)](https://github.com/NIH-NICHD-Ecosystem/UserStories/blob/main/stories/storyID-74.md) </li></ul> | I would like to enter the data about these participants into a public GenAI tool to jump-start my analysis, but I am not sure this is allowed| My goal is to understand how GenAI companies handle data input into their tools to determine whether this conflicts with legal or IRB requirements or what the participants agreed to in the consent form |
|S75 | [As a researcher, I want to use GenAI to run statistical analysis on genetic, clinical, and other health data from a controlled access data repository and generate graphs and other visuals ](https://github.com/NIH-NICHD-Ecosystem/UserStories/blob/main/stories/storyID-75.md)  </li></ul> | This requires entering the data into the tool, but I am not sure this is allowed| My goal is to understand how GenAI companies handle data input into their tools to determine whether this conflicts with the provisions of my data use agreement | 
|S76 | [As a repository curation team, I want to map submitted clinical data to a standard ontology (e.g., LOINC) using GenAI tools ](https://github.com/NIH-NICHD-Ecosystem/UserStories/blob/main/stories/storyID-76.md)  </li></ul> | The data, while de-identified, are sensitive human data that must be kept secure| My goal is to understand how GenAI companies handle data input into their tools to determine whether this conflicts with security requirements |
